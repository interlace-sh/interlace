# TPC-DI Benchmark Project

TPC-DI (Transaction Processing Performance Council - Data Integration) benchmark implementation using Interlace. This project models a financial brokerage data warehouse with complete ETL workflows.

## Overview

TPC-DI focuses on data integration workflows for a financial brokerage:
- **Extract**: Pull data from customer management, trading, and market systems
- **Transform**: Clean, validate, enrich, and calculate derived metrics
- **Load**: Populate dimension and fact tables in a star schema

## Quick Start

### 1. Generate Test Data

```bash
cd projects/tpcdi

# Generate data with default scale factor (SF=1: ~1000 customers)
python generate_data.py

# Or specify scale factor
python generate_data.py --scale-factor 10  # ~10,000 customers
```

### 2. Run the ETL Pipeline

```bash
# Run all models
interlace run

# Or run specific layers
interlace run --tag source    # Extract only
interlace run --tag staging   # Transform only
interlace run --tag warehouse # Load only
```

## Project Structure

```
tpcdi/
├── config.yaml              # Project configuration
├── generate_data.py         # Data generation script
├── models/
│   ├── sources/             # Extract layer (E)
│   │   ├── customer_source.py    # Customer, account, broker
│   │   ├── security_source.py    # Company, security
│   │   ├── trade_source.py       # Trades, holdings, watches, market
│   │   └── reference_source.py   # Date/time dimensions
│   ├── staging/             # Transform layer (T)
│   │   ├── customer_staging.py   # Customer transformations
│   │   ├── security_staging.py   # Security transformations
│   │   └── trade_staging.py      # Trade transformations
│   └── warehouse/           # Load layer (L)
│       ├── dim_customer.py       # Dimension tables
│       ├── fact_transaction.py   # Fact tables
│       └── aggregated_metrics.py # Aggregations
└── data/
    ├── raw/                 # Generated source CSV files
    └── dev/                 # DuckDB database
```

## Data Model

### Dimensions (7 tables)
| Table | Description | Strategy |
|-------|-------------|----------|
| `dim_customer` | Customer master with SCD Type 2 fields | merge_by_key |
| `dim_account` | Brokerage accounts | merge_by_key |
| `dim_broker` | Financial advisors | merge_by_key |
| `dim_company` | Public companies | merge_by_key |
| `dim_security` | Tradeable securities | merge_by_key |
| `dim_date` | Calendar dimension | replace |
| `dim_time` | Time of day dimension | replace |

### Facts (5 tables)
| Table | Description | Strategy |
|-------|-------------|----------|
| `fact_trade` | Buy/sell transactions | append |
| `fact_holding` | Current portfolio positions | replace |
| `fact_watch` | Customer watch lists | replace |
| `fact_market_history` | Daily OHLC prices | append |
| `fact_cash_balance` | Account cash snapshots | append |

### Aggregations (5 tables)
| Table | Description |
|-------|-------------|
| `agg_customer_portfolio` | Portfolio value per customer |
| `agg_broker_performance` | Broker activity and commission |
| `agg_security_performance` | Security trading statistics |
| `agg_daily_trading_summary` | Daily trading volume |
| `agg_state_summary` | Geographic customer distribution |

## ETL Pipeline

### Extract Phase (Sources)
- Load CSV files generated by `generate_data.py`
- Graceful handling of missing files (returns empty DataFrame)
- Uses pandas for I/O only (following Interlace best practices)

### Transform Phase (Staging)
- Data validation (filter null required fields)
- Standardization (uppercase/lowercase, trimming)
- Enrichment (full_name, trade_value, unrealized_gain)
- All transformations use Ibis expressions (lazy evaluation)

### Load Phase (Warehouse)
- Dimension tables with merge_by_key for incremental updates
- Fact tables with append for transactions, replace for snapshots
- Aggregations with replace for recalculated metrics

## Dependency Graph

```
Reference Data:
  src_dim_date ────────────────────────────────> dim_date
  src_dim_time ────────────────────────────────> dim_time

Customer Pipeline:
  src_customer ──> stg_customer ──> dim_customer ──┐
  src_account  ──> stg_account  ──> dim_account  ──┼──> agg_customer_portfolio
  src_broker   ──> stg_broker   ──> dim_broker   ──┼──> agg_broker_performance
                                                   └──> agg_state_summary

Security Pipeline:
  src_company  ──> stg_company  ──> dim_company  ──┐
  src_security ──> stg_security ──> dim_security ──┴──> agg_security_performance

Trade Pipeline:
  src_trade         ──> stg_trade         ──> fact_trade         ──> agg_daily_trading_summary
  src_holding       ──> stg_holding       ──> fact_holding       ──> agg_customer_portfolio
  src_watch         ──> stg_watch         ──> fact_watch
  src_market_history ──> stg_market_history ──> fact_market_history ──> agg_security_performance
  src_cash_balance  ──> stg_cash_balance  ──> fact_cash_balance
```

## Data Generation

The `generate_data.py` script creates realistic synthetic data:

| Entity | SF=1 | SF=10 | SF=100 |
|--------|------|-------|--------|
| Customers | 1,000 | 10,000 | 100,000 |
| Brokers | 50 | 500 | 5,000 |
| Companies | 200 | 2,000 | 20,000 |
| Securities | 500 | 5,000 | 50,000 |
| Accounts | ~3,000 | ~30,000 | ~300,000 |
| Trades | ~30,000 | ~300,000 | ~3,000,000 |
| Market History | ~130,000 | ~1,300,000 | ~13,000,000 |

```bash
# Generate with custom settings
python generate_data.py \
  --scale-factor 10 \
  --seed 12345 \
  --output data/raw
```

## Quality Checks

The config includes quality checks for key tables:
- Unique constraints on primary keys
- Not null checks on required fields
- Accepted values for status columns
- Row count minimums

## Materialization Strategies

| Layer | Strategy | Rationale |
|-------|----------|-----------|
| Sources | replace | Full refresh from files |
| Staging | replace | Reapply transformations |
| Dimensions | merge_by_key | Incremental updates |
| Facts (transactions) | append | Historical log |
| Facts (snapshots) | replace | Point-in-time state |
| Aggregations | replace | Recalculate from facts |

## TPC-DI Compliance

This implementation covers key TPC-DI concepts:

| Feature | Status | Notes |
|---------|--------|-------|
| Star schema | ✅ | 7 dimensions, 5 facts |
| ETL workflow | ✅ | Extract → Stage → Load |
| SCD Type 2 fields | ✅ | effective_date, end_date, is_current |
| Incremental loads | ✅ | merge_by_key strategy |
| Data quality | ✅ | Validation in staging |
| Calculated fields | ✅ | trade_value, unrealized_gain, etc. |
| Historical tracking | ⚠️ | Fields present, full SCD2 requires additional features |
| Batch processing | ✅ | Append strategy for facts |

## Resources

- [TPC-DI Specification](https://www.tpc.org/tpcdi/)
- [Interlace Documentation](https://interlace.sh)
- [Star Schema Design](https://en.wikipedia.org/wiki/Star_schema)
